<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Lecture · Scientific Programming in Julia</title><meta name="title" content="Lecture · Scientific Programming in Julia"/><meta property="og:title" content="Lecture · Scientific Programming in Julia"/><meta property="twitter:title" content="Lecture · Scientific Programming in Julia"/><meta name="description" content="Documentation for Scientific Programming in Julia."/><meta property="og:description" content="Documentation for Scientific Programming in Julia."/><meta property="twitter:description" content="Documentation for Scientific Programming in Julia."/><meta property="og:url" content="https://JuliaTeachingCTU.github.io/Scientific-Programming-in-Julia/lecture_12/lecture/"/><meta property="twitter:url" content="https://JuliaTeachingCTU.github.io/Scientific-Programming-in-Julia/lecture_12/lecture/"/><link rel="canonical" href="https://JuliaTeachingCTU.github.io/Scientific-Programming-in-Julia/lecture_12/lecture/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/onlinestats.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Scientific Programming in Julia logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Scientific Programming in Julia logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Scientific Programming in Julia</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../installation/">Installation</a></li><li><a class="tocitem" href="../../projects/">Projects</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Introduction</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/motivation/">Motivation</a></li><li><a class="tocitem" href="../../lecture_01/basics/">Basics</a></li><li><a class="tocitem" href="../../lecture_01/demo/">Examples</a></li><li><a class="tocitem" href="../../lecture_01/outline/">Outline</a></li><li><a class="tocitem" href="../../lecture_01/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_01/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: The power of type system &amp; multiple dispatch</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_02/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_02/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Design patterns</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_03/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_03/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Package development, unit tests &amp; CI</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_04/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_04/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Performance benchmarking</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_05/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_05/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Lanuage introspection</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_06/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_06/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">7: Macros</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_07/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_07/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_07/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">8: Automatic differentiation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_08/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_08/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">9: Intermediate representation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_09/lab/">Lab</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">10: Parallel programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_10/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_10/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox" checked/><label class="tocitem" for="menuitem-14"><span class="docs-label">12: Ordinary Differential Equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Lecture</a><ul class="internal"><li><a class="tocitem" href="#Uncertainty-propagation"><span>Uncertainty propagation</span></a></li><li><a class="tocitem" href="#Vector-uncertainty"><span>Vector uncertainty</span></a></li></ul></li><li><a class="tocitem" href="../lab/">Lab</a></li><li><a class="tocitem" href="../hw/">Homework</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">12: Ordinary Differential Equations</a></li><li class="is-active"><a href>Lecture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Lecture</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaTeachingCTU/Scientific-Programming-in-Julia/blob/2023W/docs/src/lecture_12/lecture.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="lec12"><a class="docs-heading-anchor" href="#lec12">Uncertainty Propagation in Ordinary Differential Equations</a><a id="lec12-1"></a><a class="docs-heading-anchor-permalink" href="#lec12" title="Permalink"></a></h1><p>Differential equations are commonly used in science to describe many aspects of the physical world, ranging from dynamical systems and curves in space to complex multi-physics phenomena. </p><p>As an example, consider a simple non-linear ordinary differential equation:</p><p class="math-container">\[\begin{align}
\dot{x}&amp;=\alpha x-\beta xy,\\\dot{y}&amp;=-\delta y+\gamma xy, 
\end{align}\]</p><p>Which describes behavior of a predator-pray models in continuous times:</p><ul><li>x is the population of prey (sheep),</li><li>y is the population of predator (wolfes)</li><li>derivatives represent instantaneous growth rates of the populations</li><li><span>$t$</span> is the time and <span>$\alpha, \beta, \gamma, \delta$</span> are parameters.</li></ul><p>Can be written in vector arguments <span>$\mathbf{x}=[x,y]$</span>:</p><p class="math-container">\[\frac{d\mathbf{x}}{dt}=f(\mathbf{x},\theta)\]</p><p>with arbitrary function <span>$f$</span> with vector of parameters <span>$\theta$</span>.</p><p>The first steps we may want to do with an ODE is to see it&#39;s evolution in time. The most simple approach is to discretize the time axis into steps: <span>$t = [t_1, t_2, t_3, \ldots t_T]$</span> and evaluate solution at these points.</p><p>Replacing derivatives by differences:</p><p class="math-container">\[\dot x \leftarrow \frac{x_t-x_{t-1}}{\Delta t}\]</p><p>we can derive a general  scheme (Euler solution):</p><p class="math-container">\[\mathbf{x}_t = \mathbf{x}_{t-1} + \Delta{}t f(\mathbf{x}_t,\theta)\]</p><p>which can be written genericaly in julia :</p><pre><code class="language-julia hljs">
function f(x,θ)
  α,β,γ,δ = θ
  x1,x2=x
   dx1 = α*x1 - β*x1*x2
   dx2 = δ*x1*x2 - γ*x2
  [dx1,dx2]
end

function solve(f,x0::AbstractVector,θ,dt,N)
  X = hcat([zero(x0) for i=1:N]...)
  X[:,1]=x0
  for t=1:N-1
     X[:,t+1]=X[:,t]+dt*f(X[:,t],θ)
  end
  X
end</code></pre><p>Is simple and working (with sufficienty small <span>$dt$</span>):</p><p><img src="../lotka.svg" alt/></p><p>ODE of this kind is an example of a &quot;complex&quot; simulation code that we may want to use, interact with, modify or incorporate into a more complex scheme.</p><ul><li>we will test how to re-define the elementary operations using custom types, automatic differentiation and automatic code generation</li><li>we will redefine the plotting operation to display the new type correctly</li><li>we will use composition to incorporate the ODE into a more complex solver</li></ul><h2 id="Uncertainty-propagation"><a class="docs-heading-anchor" href="#Uncertainty-propagation">Uncertainty propagation</a><a id="Uncertainty-propagation-1"></a><a class="docs-heading-anchor-permalink" href="#Uncertainty-propagation" title="Permalink"></a></h2><p>Prediction of the ODE model is valid only if all parameters and all initial conditions are accurate. This is almost never the case. While the number of sheep can be known, the number of wolfes in a forest is more uncertain. The same model holds for predator-prey in insects where the number of individuals can be only estimated.</p><p>Uncertain initial conditions:</p><ul><li>number of predators and prey given by a probability distribution </li><li>interval <span>$[0.8,1.2]$</span> corresponds to uniform distribution <span>$U(0.8,1.2)$</span></li><li>gaussian <span>$N(\mu,\sigma)$</span>, with mean <span>$\mu$</span> and standard deviation <span>$\sigma$</span> e.g. <span>$N(1,0.1)$</span></li><li>more complicated distributions are more realistic (the number of animals is not negative!)</li></ul><h3 id="Ensemble-approach"><a class="docs-heading-anchor" href="#Ensemble-approach">Ensemble approach</a><a id="Ensemble-approach-1"></a><a class="docs-heading-anchor-permalink" href="#Ensemble-approach" title="Permalink"></a></h3><p>The most simple approach is to represent distribution by an empirical density = discrete samples.</p><p class="math-container">\[p(\mathbf{x})\approx \frac{1}{K}\sum_{k=1}^{K} \delta(\mathbf{x}-\mathbf{x}^{(k)})\]</p><p>In the case of a Gaussian, we just sample:</p><pre><code class="language-julia hljs">K = 10
X0 = [x0 .+ 0.1*randn(2) for _=1:K]         # samples of initial conditions
Xens=[X=solve(f,X0[i],θ0,dt,N) for i=1:K]   # solve multiple times</code></pre><p>(can be implemented more elegantly using multiple dispatch on Vector{Vector})</p><p><img src="../LV_ensemble.svg" alt/></p><p>While it is very simple and universal, it may become hard to interpret. </p><ul><li>What is the probability that it will higher than <span>$x_{max}$</span>?</li><li>Improving accuracy with higher number of samples (expensive!)</li></ul><h3 id="Propagating-a-Gaussian"><a class="docs-heading-anchor" href="#Propagating-a-Gaussian">Propagating a Gaussian</a><a id="Propagating-a-Gaussian-1"></a><a class="docs-heading-anchor-permalink" href="#Propagating-a-Gaussian" title="Permalink"></a></h3><p>Propagation of uncertainty has been studied in many areas of science. Relation between accuracy and computational speed is always a tradeoff.</p><p>A common appoach to propagation of uncertainty is linearized Gaussian:</p><ul><li>variable <span>$x$</span> is represented by gaussian <span>$N(\mu,\sigma)$</span></li><li>transformation of addition: <span>$x+a\sim N(\mu+a,\sigma)$</span></li><li>transformation of multiplication: <span>$a*x\sim N(a*\mu,a*\sigma)$</span></li><li>general transformation approximated:</li></ul><p class="math-container">\[g(x)\sim N(g(\mu),g&#39;(\mu)*\sigma)\]</p><p>This can be efficienty implemented in Julia:</p><pre><code class="language-julia hljs">struct GNum{T} where T&lt;:Real
  μ::T
  σ::T
end
import Base: +, *
+(x::GaussNum{T},a::T) where T =GaussNum(x.μ+a,x.σ)
+(a::T,x::GaussNum{T}) where T =GaussNum(x.μ+a,x.σ)
*(x::GaussNum{T},a::T) where T =GaussNum(x.μ*a,a*x.σ)
*(a::T,x::GaussNum{T}) where T =GaussNum(x.μ*a,a*x.σ)</code></pre><p>For the ODE we need multiplication of two Gaussians. Using Taylor expansion and neglecting covariances:</p><p class="math-container">\[g(x_1,x_2)=N\left(g(\mu_1,\mu_2), \sqrt{\left(\frac{dg}{dx_1}(\mu_1,\mu_2)\sigma_1\right)^2 + \left(\frac{dg}{dx_2}(\mu_1,\mu_2)\sigma_2\right)^2}\right)\]</p><p>which trivially applies to sum: <span>$x_1+x_2=N(\mu_1+\mu_2, \sqrt{\sigma_1^2 + \sigma_2^2})$</span></p><pre><code class="language-julia hljs">+(x1::GaussNum{T},x2::GaussNum{T}) where T =GaussNum(x1.μ+x2.μ,sqrt(x1.σ.^2 + x2.σ.^2))
*(x1::GaussNum{T},x2::GaussNum{T}) where T =GaussNum(x1.μ*x2.μ, sqrt(x2.μ*x1.σ.^2 + x1.μ*x2.σ.^2))
</code></pre><p>Following the principle of defining the necessary functions on the type, we can make it pass through the ODE:</p><ul><li>it is necessary to define new initialization (functions <code>zero</code>)</li><li>define nice-looking constructor (<span>$±$</span>)<pre><code class="language-julia hljs">±(a::T,b::T) where T:&lt;Real =GaussNum(a,b)</code></pre></li></ul><pre><code class="language-julia hljs">GX=solve(f,[1.0±0.1,1.0±0.1],[0.1,0.2,0.3,0.2],0.1,1000)</code></pre><p><img src="../LV_GaussNum.svg" alt/></p><ul><li>function overloading follows a deterministic procedure =&gt; can be automated (macro, generated functions)</li></ul><h3 id="Flexibility"><a class="docs-heading-anchor" href="#Flexibility">Flexibility</a><a id="Flexibility-1"></a><a class="docs-heading-anchor-permalink" href="#Flexibility" title="Permalink"></a></h3><p>The great advantage of the former model was the ability to run an arbitrary code with uncertainty at an arbitrary number.</p><p>For example, we may know the initial conditions, but do not know the parameter value.</p><pre><code class="language-julia hljs">GX=solve(f,[1.0±0.1,1.0±0.1],[0.1±0.1,0.2,0.3,0.2],0.1,1000)</code></pre><p><img src="../LV_GaussNum2.svg" alt/></p><h3 id="Disadvantage"><a class="docs-heading-anchor" href="#Disadvantage">Disadvantage</a><a id="Disadvantage-1"></a><a class="docs-heading-anchor-permalink" href="#Disadvantage" title="Permalink"></a></h3><p>The result does not correspond to the ensemble version above.</p><ul><li>we have ignored the covariances</li><li>extension to version with covariances is possible by keeping track of the correlations (<code>Measurements.jl</code>), where other variables are stored in a dictionary:<ul><li>correlations found by language manipulations</li><li>very flexible and easy-to-use</li><li>discovering the covariances requires to build the covariance from <code>ids</code>. (Expensive if done too often).</li></ul></li></ul><h2 id="Vector-uncertainty"><a class="docs-heading-anchor" href="#Vector-uncertainty">Vector uncertainty</a><a id="Vector-uncertainty-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-uncertainty" title="Permalink"></a></h2><p>The previous simple approach ignores the covariances between variables. Even if we tract covariances linearly in the same fashion (<span>$Measurements.jl$</span>), the approach will suffer from a loss of precision under non-linearity. </p><p><img src="https://photos1.blogger.com/blogger/5955/293/1600/unscented-transform-explained.jpg" alt/></p><ul><li>The linearization-based approach propogates through the non-linearity only the mean and models its neighborhood by a plane.</li><li>Propagating all samples is too expensive</li><li>Methods based on quadrature or cubature rules are a compromise</li></ul><p>The cubature approach is based on moment matching:</p><p class="math-container">\[\mu_g = \int g(x) p(x) dx\]</p><p>for which is <span>$g(\mu)$</span> poor approximation, corresponding to:</p><p class="math-container">\[\mu_g = g(\mu) = \int g(x) \delta(x-\mu) dx\]</p><p>For Gaussian distribution, we can use a smarter integration rule, called the Gauss-Hermite quadrature:</p><p class="math-container">\[\mu_g = \int g(x) p(x) dx \approx \sum_{j=1}^J w_j g(x_j)\]</p><p>where <span>$x_j$</span> are prescribed quadrature points (see e.g. <img src="https://www.efunda.com/math/num_integration/findgausshermite.cfm" alt="online tables"/>)</p><p>In multivariate setting, the same problem is typically solved with the aim to reduce the computational cost to linear complexity with dimension. Most often aimimg at <span>$O(2d)$</span> complexity where <span>$d$</span> is the  dimension of vector <span>$x$</span>.</p><p>One of the most popular approaches today is based on cubature rules approximating the Gaussian in radial-spherical coordinates.</p><h3 id="Cubature-rules"><a class="docs-heading-anchor" href="#Cubature-rules">Cubature rules</a><a id="Cubature-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Cubature-rules" title="Permalink"></a></h3><p>Consider Gaussian distribution with mean <span>$\mu$</span> and covariance matrix <span>$\Sigma$</span> that is positive definite with square root <span>$\sqrt\Sigma$</span>, such that <span>$\sqrt\Sigma \sqrt\Sigma^T=\Sigma$</span>. The quadrature pints are:</p><p class="math-container">\[x_i = \mu + \sqrt\Sigma q_i\]</p><p class="math-container">\[\begin{align}
q_{1}&amp;=\sqrt{d}\begin{bmatrix}1\\
0\\
\vdots
\end{bmatrix}
&amp;
q_{2}&amp;=\sqrt{d}\begin{bmatrix}0\\
1\\
\vdots
\end{bmatrix} \ldots 
&amp;
q_{d+1}&amp;=\sqrt{d}\begin{bmatrix}-1\\
0\\
\vdots
\end{bmatrix}
q_{d+2}&amp;=\sqrt{d}\begin{bmatrix}0\\
-1\\
\vdots
\end{bmatrix} \ldots
\end{align}\]</p><p>that can be composed into a matrix <span>$Q=[q_1,\ldots q_{2d}]$</span> that is constant:</p><p class="math-container">\[Q = \sqrt{d} [ I_d, -I_d]\]</p><p><img src="../cubature.png" alt/></p><p>Those quadrature points are in integration weighted by:</p><p class="math-container">\[w_i = \frac{1}{2d}, i=1,\ldots,2d\]</p><p>where <span>$d$</span> is dimension of the vectors.</p><p>The quadrature points are propogated through the non-linearity in parallel (<span>$x_i&#39;=g(x_i)$</span>) and the resulting Gaussian distribution is:</p><p class="math-container">\[\begin{align}
x&#39; &amp; \sim N(\mu&#39;,\Sigma&#39;)\\
\mu&#39; &amp; = \frac{1}{2d}\sum_{j=1}^{2d} x&#39;_i\\
\Sigma &amp;= \frac{1}{2d}\sum_{j=1}^{2d} (x&#39;_i-\mu&#39;)^T (x&#39;_i-\mu&#39;)
\end{align}\]</p><p>It is easy to check that if the sigma-points are propagated through an identity, they preserve the mean and variance. </p><p class="math-container">\[\begin{align}
\mu&#39; &amp; = \frac{1}{2d}\sum_{j=1}^{2d} (\mu + \sqrt{\Sigma}q_i)\\
 &amp; = \frac{1}{2d}(2d\mu + \sqrt{\Sigma} \sum_{j=1}^{2d} (q_i)
 &amp; = \mu
\end{align}
\]</p><p>For our example:</p><p><img src="../LV_Quadrics.svg" alt/></p><ul><li>only 4 trajectories propagated deterministically</li><li>can not be implemented using a single number type<ul><li>the number of points to store is proportional to the dimension</li><li>manipulation requires operations from linear algebra</li></ul></li><li>moving to representations in vector form<ul><li>simple for initial conditions,</li><li>how to extend to operate also on parameters?</li></ul></li></ul><h3 id="Smarter-implementation"><a class="docs-heading-anchor" href="#Smarter-implementation">Smarter implementation</a><a id="Smarter-implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Smarter-implementation" title="Permalink"></a></h3><p>Easiest solution is to put the corresponding parts of the problem together:</p><ul><li>ode function <span>$f$</span>, </li><li>its state <span>$x0$</span>,</li><li>and parameters <span>$θ$</span></li></ul><p>can be wrapped into an ODEProblem</p><pre><code class="language-julia hljs">struct ODEProblem{F,T,X&lt;:AbstractVector,P&lt;:AbstractVector}
    f::F
    tspan::T
    x0::X
    θ::P
end</code></pre><ul><li>the solver can operate on the ODEProbelm type</li></ul><h3 id="Unceratinty-propagation-in-vectors"><a class="docs-heading-anchor" href="#Unceratinty-propagation-in-vectors">Unceratinty propagation in vectors</a><a id="Unceratinty-propagation-in-vectors-1"></a><a class="docs-heading-anchor-permalink" href="#Unceratinty-propagation-in-vectors" title="Permalink"></a></h3><p>Example: consider uncertainty in state <span>$[x_1,x_2]$</span> and the first parameter <span>$\theta_1$</span>. </p><p>Quick and dirty: </p><pre><code class="language-julia hljs">getuncertainty(o::ODEProblem) = [o.u0[1:2];o.θ[1]]
setuncertainty!(o::ODEProblem,x::AbstractVector) = o.u0[1:2]=x[1:2],o.θ[1]=x[3]</code></pre><p>and write a general Cubature solver using multiple dispatch.</p><p>Practical issues:</p><ul><li>how to check bounds? (Asserts)</li><li>what if we provide an incompatible ODEProblem</li><li>define a type that specifies the type of uncertainty? </li></ul><pre><code class="language-julia hljs">struct GaussODEProblem
  mean::ODEProblem
  unc_in_u # any indexing type accepted by to_index()
  unc_in_θ
  sqΣ0
end</code></pre><p>We can dispatch the cubature solver on GaussODEProblem and the ordinary <span>$solve$</span> on GaussODEProblem.OP internally.</p><pre><code class="language-julia hljs">getmean(gop::GaussODEProblem) =[ gop.mean.x0[gop.unc_in_u];gop.mean.θ[gop.unc_in_θ]]
setmean!(gop::GaussODEProblem,x::AbstractVector) = begin 
  gop.mean.x0[gop.unc_in_u]=x[1:length(gop.unc_in_u)]
  gop.mean.θ[gop.unc_in_θ]=x[length(gop.unc_in_u).+[1:length(gop.unc_in_θ)]] 
end</code></pre><p>Constructor accepts an ODEProblem with uncertain numbers and converts it to GaussODEProblem:</p><ul><li>goes through ODEProblem <span>$x0$</span> and <span>$θ$</span> fields and checks their types</li><li>replaces GaussNums in ODEProblem  by ordinary numbers</li><li>remembers indices of GaussNum in <span>$x0$</span> and <span>$θ$</span></li><li>copies standard deviations in GaussNum to <span>$sqΣ0$</span></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../lecture_10/hw/">« Homework</a><a class="docs-footer-nextpage" href="../lab/">Lab »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Thursday 14 December 2023 13:31">Thursday 14 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
