<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Lecture Â· Scientific Programming in Julia</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://JuliaTeachingCTU.github.io/Scientific-Programming-in-Julia/lecture_13/lecture/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Scientific Programming in Julia logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Scientific Programming in Julia logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Scientific Programming in Julia</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../installation/">Installation</a></li><li><a class="tocitem" href="../../projects/">Projects</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Introduction</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/motivation/">Motivation</a></li><li><a class="tocitem" href="../../lecture_01/basics/">Basics</a></li><li><a class="tocitem" href="../../lecture_01/demo/">Examples</a></li><li><a class="tocitem" href="../../lecture_01/outline/">Outline</a></li><li><a class="tocitem" href="../../lecture_01/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_01/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: The power of Type System &amp; multiple dispatch</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_02/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_02/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Design patterns</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_03/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_03/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Packages development, Unit Tests &amp; CI</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_04/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_04/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Benchmarking, profiling, and performance gotchas</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_05/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_05/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Language introspection</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_06/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_06/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">7: Macros</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_07/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_07/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_07/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">8: Introduction to automatic differentiation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_08/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_08/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">9: Manipulating intermediate representation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_09/lab/">Lab</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">10: Different levels of parallel programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_10/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_10/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">11: Julia for GPU programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_11/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_11/lab/">Lab</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-15" type="checkbox"/><label class="tocitem" for="menuitem-15"><span class="docs-label">12: Uncertainty propagation in ODE</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_12/lecture/">Lecture</a></li><li><a class="tocitem" href="../../lecture_12/lab/">Lab</a></li><li><a class="tocitem" href="../../lecture_12/hw/">Homework</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-16" type="checkbox" checked/><label class="tocitem" for="menuitem-16"><span class="docs-label">13: Learning ODE from data</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../lab/">Lab</a></li><li class="is-active"><a class="tocitem" href>Lecture</a><ul class="internal"><li><a class="tocitem" href="#Fitting-ODE-solution-to-data"><span>Fitting ODE solution to data</span></a></li><li><a class="tocitem" href="#Extending-the-ODE"><span>Extending the ODE</span></a></li><li class="toplevel"><a class="tocitem" href="#Neural-Networks-in-Julia"><span>Neural Networks in Julia</span></a></li><li><a class="tocitem" href="#Multi-layer-perceptron"><span>Multi-layer perceptron</span></a></li><li><a class="tocitem" href="#FastChain"><span>FastChain</span></a></li><li class="toplevel"><a class="tocitem" href="#Neural-Networks-in-ODEs:"><span>Neural Networks in ODEs:</span></a></li><li><a class="tocitem" href="#Neural-Lotka-Volterra"><span>Neural Lotka-Volterra</span></a></li><li><a class="tocitem" href="#Physics-informed-Neural-Network"><span>Physics-informed Neural Network</span></a></li><li class="toplevel"><a class="tocitem" href="#Data-assimilation-in-uncertain-ODEs"><span>Data assimilation in uncertain ODEs</span></a></li><li><a class="tocitem" href="#Bayesian-filtering"><span>Bayesian filtering</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">13: Learning ODE from data</a></li><li class="is-active"><a href>Lecture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Lecture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaTeachingCTU/Scientific-Programming-in-Julia/blob/master/docs/src/lecture_13/lecture.md#" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Data-driven-Ordinary-Differential-Equations"><a class="docs-heading-anchor" href="#Data-driven-Ordinary-Differential-Equations">Data-driven Ordinary Differential Equations</a><a id="Data-driven-Ordinary-Differential-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Data-driven-Ordinary-Differential-Equations" title="Permalink"></a></h1><p>We have looked into the uncertainty propagation through an ODE in the previous lecture. The uncertainty may stem from:</p><ul><li>unknown boundary conditions (e.g. initial conditions)</li><li>unknown parameters (reproduction rates, etc.)</li><li>missing terms (hidden dynamics) of an ODE</li></ul><p>The uncertainty in the solution can be reduced when data are available. In this Lecture we will look into:</p><ul><li>estimating parameters of an ODE to match the data, </li><li>learning unknown ODEs using Neural Networks </li><li>using neural networks as a solver of Neural networks</li><li>respecting uncertainty in the data <ul><li>reduction of uncertainty incrementally with the data,</li><li>Gaussian filter using Cubature rules</li></ul></li></ul><h2 id="Fitting-ODE-solution-to-data"><a class="docs-heading-anchor" href="#Fitting-ODE-solution-to-data">Fitting ODE solution to data</a><a id="Fitting-ODE-solution-to-data-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-ODE-solution-to-data" title="Permalink"></a></h2><p>Since the ODE solver is a function like any other, it is possible to use general-purpose optimizers to optimize parameters of the ODE to match the output.</p><pre><code class="language-julia hljs">using Optim

Î¸2=[0.2,0.2,0.3,0.1]
prob = ODEProblem(f,tspan,[1.0,1.0],Î¸2)
t,X=solve(prob, RK2(0.2))

function loss(Î¸in,prob::ODEProblem,Y)
    prob.Î¸.=Î¸in
    t,Xn=solve(prob,RK2(0.2))
    sum((Y.-Xn).^2)
end
Î¸opt = [0.1,0.2,0.3,0.1]
O=Optim.optimize(Î¸-&gt;loss(Î¸,prob,X),Î¸opt)
Olb=Optim.optimize(Î¸-&gt;loss(Î¸,prob,X),Î¸opt,LBFGS())</code></pre><ul><li>using the power of automatic differentiation (of the numerical solver)</li><li>in the case of ODE, the gradients can be modified to use the information about exact derivatives (adjoints) </li></ul><h2 id="Extending-the-ODE"><a class="docs-heading-anchor" href="#Extending-the-ODE">Extending the ODE</a><a id="Extending-the-ODE-1"></a><a class="docs-heading-anchor-permalink" href="#Extending-the-ODE" title="Permalink"></a></h2><p>The previous approach will work only if the data were generated by the exact ODE. If the structure of ODE is different, e.g. some terms are missing, we can never find an exact fit.</p><p class="math-container">\[\begin{align}
\dot{x}&amp;=\alpha x-\beta xy + {\color{red} \omega y},\\\
\dot{y}&amp;=-\delta y+\gamma xy, 
\end{align}\]</p><p>For example: with <span>$\omega = 0.1$</span> the trajectory becomes:</p><p><img src="../LV_omega.svg" alt/></p><p>We could &quot;guess&quot; what is the missing term or add a black box (neural network). The whole problem will become finding parameters <span>$\theta = [\theta_{ODE},\theta_{NN}]$</span>. </p><p class="math-container">\[\frac{d\mathbf{x}}{dt}=f(\mathbf{x},\theta_{ODE}) + NN(\mathbf{x},\theta_{NN})\]</p><p>In the limiting case, we may learn only the network:</p><p class="math-container">\[\frac{d\mathbf{x}}{dt}= NN(\mathbf{x},\theta_{NN})\]</p><p>known as the &quot;Neural ODE&quot; (Chen et. al. 2018). We will try to learn neural ODE for the extended systems. We need to look into neural network tools.</p><h1 id="Neural-Networks-in-Julia"><a class="docs-heading-anchor" href="#Neural-Networks-in-Julia">Neural Networks in Julia</a><a id="Neural-Networks-in-Julia-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Networks-in-Julia" title="Permalink"></a></h1><p>Many possible packages implementing Neural Networks (Flux, Knets, MXnets, tensorFlow) etc. By far the most used package is the <code>Flux.jl</code></p><h2 id="Multi-layer-perceptron"><a class="docs-heading-anchor" href="#Multi-layer-perceptron">Multi-layer perceptron</a><a id="Multi-layer-perceptron-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-layer-perceptron" title="Permalink"></a></h2><p>A simple feed-forward neural network (multi-layer-perceptron) </p><p class="math-container">\[y=Ï(W_n Ï(W_{n-1}\ldots Ï(W_{1}x+b_1)\ldots )+b_n)\]</p><p>is implemented as a <code>Chain</code> of layers:</p><pre><code class="language-julia hljs">struct Chain{T}
  layers::T
  Chain(xs...) = new{typeof(xs)}(xs)
  #...
end</code></pre><p>The layers again follow the maths, e.g. <code>Dense</code></p><pre><code class="language-julia hljs">struct Dense{F, M&lt;:AbstractMatrix, B}
  weight::M
  bias::B
  Ï::F
end

Dense(W, b) = Dense(W, b, identity)

function (a::Dense)(x::AbstractArray)
  W, b, Ï = a.weight, a.bias, a.Ï
  return Ï.(W*x .+ b)
end</code></pre><p>Building an MLP is straightforward:</p><pre><code class="language-julia hljs">nx = 2
nn = Chain(Dense(rand(nx,nx),rand(nx)))</code></pre><p>Now, we would like to optimize its parameters. It would be cumbersume to write into them.</p><h3 id="Functors.jl"><a class="docs-heading-anchor" href="#Functors.jl">Functors.jl</a><a id="Functors.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Functors.jl" title="Permalink"></a></h3><p>In Flux, the standard mechanism is to compose an <code>IdSet</code> with a list of all parameters and operate on that list. </p><pre><code class="language-julia hljs">ps = params(nn)
ps[1]</code></pre><p>Now all operations (even gradients) can be defined on the list. The gradients are stored in an `<span>$IdDict$</span> with pointer to the parameter as the key:</p><pre><code class="language-julia hljs">gs=gradient(()-&gt;sum(nn([1,2])),ps)
gs[ps[1]]</code></pre><p>This approach has benefits and drawbacks:</p><ul><li>it allows to write a very general code easily, </li><li>the list of parameters is accessible for modifications:<ul><li>removing parameter from optimization can be done by removing it from the parameter list</li><li>adding a parameter (e.g. from the ODE) allows composition of NN with other code</li></ul></li><li>it introduces an overhead<ul><li>may be negligible for large models (hundreds of hidden neurons) that are dominated by matrix manipulation.</li><li>becomes significant for low dimensional models (ODEs)</li></ul></li></ul><h2 id="FastChain"><a class="docs-heading-anchor" href="#FastChain">FastChain</a><a id="FastChain-1"></a><a class="docs-heading-anchor-permalink" href="#FastChain" title="Permalink"></a></h2><p>As an alternative, package <code>DiffEqFlux.jl</code> introduces a different concept of the Chain and Layers, called FastChain and FastLayers.</p><pre><code class="language-julia hljs">abstract type FastLayer &lt;: Function end</code></pre><p>with interface </p><pre><code class="language-julia hljs">paramlength(f) = 0
initial_params(f) = Float32[]</code></pre><p>that needs to be specialized for layers.</p><p>The layer that we will be working with is the <code>FastDense</code>:</p><pre><code class="language-julia hljs">struct FastDense{F,F2} &lt;: FastLayer
  out::Int
  in::Int
  Ï::F
  initial_params::F2
  bias::Bool
  # function FastDense(...
end</code></pre><p>It does not store its parameters but operates on an external parameter vector:</p><pre><code class="language-julia hljs">(f::FastDense)(x,p) = ((f.bias == true ) 
  ? (f.Ï.(reshape(p[1:(f.out*f.in)],f.out,f.in)*x .+ p[(f.out*f.in+1):end])) 
  : (f.Ï.(reshape(p[1:(f.out*f.in)],f.out,f.in)*x)))</code></pre><p>The same behavior is replicated in FastChain:</p><pre><code class="language-julia hljs">struct FastChain{T&lt;:Tuple} &lt;: FastLayer
  layers::T
  # function FastChain(xs...)...
end</code></pre><p>Since it is a Layer, it implements interfaces:</p><pre><code class="language-julia hljs">paramlength(c::FastChain) = sum(paramlength(x) for x in c.layers)
initial_params(c::FastChain) = vcat(initial_params.(c.layers)...)</code></pre><p>and the functor:</p><pre><code class="language-julia hljs">(c::FastChain)(x,p) = applychain(c.layers, x, p)
applychain(::Tuple{}, x, p) = x
applychain(fs::Tuple, x, p) = applychain(Base.tail(fs), first(fs)(x,p[1:paramlength(first(fs))]), p[(paramlength(first(fs))+1):end])</code></pre><p>Other types of layers using StaticArrays are defined for small networks (allocating on the stack).</p><p>The same 2x2 network can be implemented as:</p><pre><code class="language-julia hljs">using DiffEqFlux
nn=FastDense(2,2)
p = initial_params(nn)
nn([1,2],p)</code></pre><p>Effects of code composition in Julia:</p><ul><li>Toolboxes of Neural Networks in Julia are often lightweight</li><li>the tools necessary for their training are not specific to NN (AD: Zygote, Enzyme)</li><li>Combination with ODE is straigthforward</li></ul><h1 id="Neural-Networks-in-ODEs:"><a class="docs-heading-anchor" href="#Neural-Networks-in-ODEs:">Neural Networks in ODEs:</a><a id="Neural-Networks-in-ODEs:-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Networks-in-ODEs:" title="Permalink"></a></h1><p>With neural networks in place, we can now define an ODE with neural network part.</p><h2 id="Neural-Lotka-Volterra"><a class="docs-heading-anchor" href="#Neural-Lotka-Volterra">Neural Lotka-Volterra</a><a id="Neural-Lotka-Volterra-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Lotka-Volterra" title="Permalink"></a></h2><p>Consider an extension of the LV ODE by a MLP:</p><pre><code class="language-julia hljs">function fnn(x,Î¸)
    Î±, Î², Î³, Î´ = Î¸[1:4]
    xâ, xâ = x

    dxâ = Î±*xâ - Î²*xâ*xâ 
    dxâ = Î´*xâ*xâ - Î³*xâ

    [dxâ, dxâ]+nn(x,@view Î¸[5:end])
end</code></pre><p>Can be implemented via a closure (closing on nn).</p><p>Optimize using the same approach as before:</p><pre><code class="language-julia hljs">Î¸nn = [0.2,0.2,0.3,0.2,0.01*initial_params(nn)...]
probnn = ODEProblem(fnn,tspan,u0,Î¸nn)

Î¸opt = copy(Î¸nn)
O=Optim.optimize(Î¸-&gt;loss(Î¸,probnn,Xy),Î¸opt,Optim.Options(iterations=10000))</code></pre><p>The <span>$Xy$</span> data were generated with the Ï version of the ODE, with parameters <span>$\theta=[0.2,0.2,0.3,0.2,0.1]$</span>.</p><p>Optimization difficulties:</p><ul><li>the number of iteration in Nelder-Mead had to be increased</li><li>LBGFS() optimizer extremely slow</li></ul><p>Why?</p><h2 id="Physics-informed-Neural-Network"><a class="docs-heading-anchor" href="#Physics-informed-Neural-Network">Physics-informed Neural Network</a><a id="Physics-informed-Neural-Network-1"></a><a class="docs-heading-anchor-permalink" href="#Physics-informed-Neural-Network" title="Permalink"></a></h2><p>The idea is rather simple:</p><ul><li>neural network can approximate any function - why not solution to an ODE: <span>$\mathbf{x}(t)$</span></li><li>replaces methods of numerical solution (Euler, RK2)</li></ul><p>We need to define:</p><ul><li>Architecture of NN<ul><li>Neural network for the solution of Lotka-Volterra?</li></ul></li><li>the optimization objective</li></ul><p>A solution of ODE should satisfy:</p><ul><li>boundary (initial) conditions </li><li>the ODE holds at every point of teh solution on its domain</li></ul><p>While this would be difficult to satisfy in general, it is relatively simple to define on a grid. For the Lotka-Voltera problem, we have two conditions:</p><p class="math-container">\[\begin{align}
x(t)&amp;=x0 &amp;&amp; \text{for }t=0,\\
dx(t)&amp;=f(x_t), &amp;&amp; \text{for } t = \Delta{}t, 2\Delta{}t, \ldots , N\Delta{}t 
\end{align}\]</p><p>This can be summarized in a loss function:</p><p class="math-container">\[\mathcal{L}=||nn(0)-\mathbf{x}_0)|| + \frac{1}{N}\sum_{i=1}^N||f(\mathbf{x}_i)-\nabla_t nn(t_i) ||\]</p><p>This straightforward approach was proposed relatively recently (2019).</p><ul><li>the training is not easy</li><li>the need for higher-order derivatives (challenge for sourse-to-source AD)</li><li>numerical issues</li></ul><p>Very simple extension for known data:</p><p class="math-container">\[\begin{align}
\mathcal{L}=&amp;||nn(0)-\mathbf{x}_0)|| + \frac{1}{N}\sum_{i=1}^N||f(\mathbf{x}_i)-\nabla_t nn(t_i) ||\\
            &amp; + \frac{1}{M}\sum_{j=1}^M||y_j - h(nn(t_j))||
\end{align}\]</p><p>where <span>$h()$</span> is a function transforming ODE solution to observations (e.g. identity, or selection of the relevant observations).</p><p>Example will be worked out in the lab.</p><p>PINNs can be combined with Neural ODE.</p><h1 id="Data-assimilation-in-uncertain-ODEs"><a class="docs-heading-anchor" href="#Data-assimilation-in-uncertain-ODEs">Data assimilation in uncertain ODEs</a><a id="Data-assimilation-in-uncertain-ODEs-1"></a><a class="docs-heading-anchor-permalink" href="#Data-assimilation-in-uncertain-ODEs" title="Permalink"></a></h1><p>So far, we have seen optimizations of the ODEs in the form of point estimate. We have seen an almost perfect fit. This may be dangerous when:</p><ul><li>the measurement are uncertain with large possible error</li><li>the number of measurements is insufficient to fit the model.</li></ul><p>Consider the Monte Carlo simulation from the previous lecture extended for unknown parameter:</p><pre><code class="language-julia hljs">K=100
X0 = [x0 .+ 0.1*randn(2) for k=1:K]
Î¸1 =[[Î¸0[1]+0.01randn();Î¸0[2:end]] for k=1:K]
Xens=[X=solve(f,X0[i],Î¸1[i],dt,N) for i=1:K]</code></pre><p><img src="../LV_MC_param.svg" alt/></p><p>We have observed data for every 100th sample with standard deviation 0.2.</p><p><img src="../LV_MC_param_data.svg" alt/></p><p>Point estimate is the trajectory with the thick color.</p><ul><li>it is the one with minimum error</li><li>is it really the solution?</li></ul><p>Lets select all trajectories within a selected tolerance:</p><p><img src="../LV_MC_param_assim.svg" alt/></p><h2 id="Bayesian-filtering"><a class="docs-heading-anchor" href="#Bayesian-filtering">Bayesian filtering</a><a id="Bayesian-filtering-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-filtering" title="Permalink"></a></h2><p>When the data are collected sequentially, the process of reduction of the uncertainty is repeated with every new measurement. The procedure is an iteration of two steps:</p><ol><li>prediction - use ODE with uncertainty propagation to the next step,</li><li>correction - use the acquired measurement to reduce the uncertainty</li></ol><p>Example: weather forecast</p><ul><li>prediction is simulation of the earth atmosphere using PDE</li><li>correction is update of the state of the atmosphere using weather data</li></ul><p>In mathematics, it is direct application of the Bayes rule:</p><p class="math-container">\[\begin{align}
p(\mathbf{x},\mathbf{y})	&amp;=p(\mathbf{y}|\mathbf{x})p(\mathbf{x})=p(\mathbf{x}|\mathbf{y})p(\mathbf{y})\\
p(\mathbf{x}|\mathbf{y})	&amp;=\frac{p(\mathbf{y}|\mathbf{x})p(\mathbf{x})}{p(\mathbf{y})}=\frac{p(\mathbf{y}|\mathbf{x})p(\mathbf{x})}{\int p(\mathbf{y}|\mathbf{x})p(\mathbf{x})d\mathbf{x}}
\end{align}\]</p><p>Trade-off between generality and speed</p><ul><li>A implementation of the whole procedure can be done on a general level using types for probability distributions and operations on them.</li><li>How exactly are these steps implemented depends on the assumptions made on the type of model uncertainty (initial conditions, parameters, noise) and the measurement uncertainty (noise).</li></ul><p>We have done propagation of the Gaussian uncertainty through an ODE (GaussNum, Cubature rules). We will complement it by the correction step here. </p><p>State augmentation:</p><ul><li>the state variable <span>$\mathbf{x}$</span> contains all uncertain information that is required to predict the future</li><li>in the case of uncertain ODE solved above, it would be the ODE state variables (predator, prey) and the unknown parameter <span>$Î¸_1$</span>: ``\mathbf{x}=[x,y,\alpha]</li><li>we assume that the parameter is not changing in time <span>$\alpha(t_1)=\alpha(t_2)$</span></li><li>this assumption extends the ODE by an additional state: </li></ul><p class="math-container">\[\dot\alpha = 0\]</p><p>forming a set of three differential equations: <span>$\dot x, \dot y, \dot \alpha$</span>.</p><p>Observations are assumed to be a noisy transformation of the state. In our case, we would observe the prey variable:</p><p class="math-container">\[\begin{align}
\mathbf{y_t}&amp;=h(\mathbf{x}) + Ï_y e_t,  \,\,\, e_t \sim N(0,1) \\
h(\mathbf{x})&amp;= \mathbf{x}_1
\end{align}\]</p><p>Assumption of the Gaussian uncertainty in the ODE as well as the noise is one of the easiest to solve, due to nice properties of the Gaussian distribution. Specifically, joint distribution of a marginal and conditional Gaussian distribution is a Gaussian distribution:</p><p class="math-container">\[\begin{align}
p(\mathbf{x},\mathbf{y})&amp;=\mathcal{N}\left(\begin{bmatrix}\mu_{x}\\
\mu_{y}
\end{bmatrix},\begin{bmatrix}\Sigma_{xx} &amp; \Sigma_{xy}\\
\Sigma_{yx} &amp; \Sigma_{yy}
\end{bmatrix}\right)\\p(\mathbf{y})&amp;=\mathcal{N}\left(\mu_{y},\Sigma_{yy}\right)\\p(\mathbf{x}|\mathbf{y})&amp;=\mathcal{N}(\mu_{x}+\Sigma_{xy}\Sigma_{yy}^{-1}(\mathbf{y}-\mu_{y}),\Sigma_{xx}-\Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})
\end{align}\]</p><p><img src="../mvgaussian.png" alt/></p><ul><li>marginal distributions are unaffected by the correlation</li><li>the correlation determines the reduction of uncertainty in the conditional case</li></ul><p>We have uncertainty in all our unknowns <span>$p(\mathbf{x})$</span> in the form of quadrature points. We assume that the probability of observation of <span>$p(\mathbf{y}|\mathbf{x})$</span> has mean given by <span>$x$</span> and variance <span>$\sigma_y$</span>. Hence, the means can be obtained by empirical samples of the cubature points <span>$X_p$</span> and measurements corresponding to cubature points.</p><p class="math-container">\[\begin{align}
\mu_{x}&amp;=\overline{X_{p}},&amp; X_p &amp;=[\mathbf{x}_1,\ldots \mathbf{x}_{2d}]\\
 mu_{y}&amp;=\overline{Y_{p}}, &amp; Y_p &amp;=[h(\mathbf{x}_i),\ldots h(\mathbf{x}_{2d})]

\end{align}\]</p><p>e.g. if the measurements are only the <span>$x$</span> (prey variable) the <span>$y_i = x_{1,i}$</span>.</p><p>The covariance matrices can be obtained by empirical samples:</p><p class="math-container">\[\begin{align}
\Sigma_{xx}&amp;=\text{cov}(X_p,X_p)=\frac{1}{2d}\sum_{i=1}^{2d}(x{}_{i}-\mu_{x})^{T}(x_{i}-\mu_{x})\\
\Sigma_{yx}&amp;=\text{cov}(Y_p,X_p)=\frac{1}{2d}\sum_{i=1}^{2d}(y{}_{i}-\mu_{y})^{T}(x_{i}-\mu_{x}),\\
\Sigma_{yy}&amp;=\text{cov}(Y_p,Y_p)+\sigma_y^2=\frac{1}{2d}\sum_{i=1}^{2d}(y{}_{i}-\mu_{y})^{T}(y_{i}-\mu_{y})+\sigma_{y}^2,
\end{align}\]</p><p>The uncertainty reduction is then application of the conditional distribution using the obtained means and variances. A common trick is to define the Kalman gain:</p><p class="math-container">\[\begin{align}
K&amp;=\Sigma_{xy}\Sigma_{yy}^{-1},\\
\mu_{x|y}&amp;=\mu_{x}+K(\mathbf{y}-\mu_{y}),\\
\Sigma_{x|y}&amp;=\Sigma_{xx}-K\Sigma_{yx},
\end{align}\]</p><p>The full algorithms is then as follows:</p><ol><li>generate cubature points from their mean <span>$\mu_x$</span> and <span>$\Sigma_{xx}$</span></li><li>run propagation of the cubature points <span>$X_p$</span> through the ODE up to the time of the measurements,</li><li>compute their mean <span>$\mu_x$</span> and variance <span>$\Sigma_{xx}$</span>,</li><li>for each cubature point compute the predicted measurement, <span>$Y_p$</span>. Compute  mean <span>$\mu_y$</span> and covariance <span>$\Sigma_{yy}$</span></li><li>Compute the reduced uncertainty mean <span>$\mu_{x|y}$</span> and <span>$\Sigma_{x|y}$</span>. These will be used to generate new cubature points in step 1.</li></ol><p>Detailed implementation will follow in the lab.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../lab/">Â« Lab</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Friday 9 December 2022 17:35">Friday 9 December 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
